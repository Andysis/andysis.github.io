---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# ğŸ“– å·¥ä½œä¸æ•™è‚²
- *2021.02 - è‡³ä»Š*, æ­¦æ±‰å…‰ç”µå›½å®¶ç ”ç©¶ä¸­å¿ƒï¼Œåä¸­ç§‘æŠ€å¤§å­¦ï¼Œå‰¯æ•™æˆï¼Œå›½å®¶åƒäºº[æå¼ºæ•™æˆ](http://bmp.hust.edu.cn/info/1151/2222.htm)è¯¾é¢˜ç»„ã€‚
- *2019.08 - 2020.08*, å·¥å­¦é™¢ï¼Œé¦™æ¸¯ç§‘æŠ€å¤§å­¦ï¼Œåšå£«åç ”ç©¶å‘˜ï¼Œå‰¯æ ¡é•¿å…¼å·¥å­¦é™¢é™¢é•¿[éƒ‘å…‰å»·æ•™æˆ](https://seng.hkust.edu.hk/about/people/faculty/tim-kwang-ting-cheng)è¯¾é¢˜ç»„ã€‚
- *2015.09 - 2019.06*, ç”µå­ä¿¡æ¯ä¸é€šä¿¡å­¦é™¢ï¼Œåä¸­ç§‘æŠ€å¤§å­¦ï¼Œåšå£«ç ”ç©¶ç”Ÿï¼Œå›½å®¶ä¼˜é’[æ¨æ¬£æ•™æˆ](https://sites.google.com/view/xinyang/home)è¯¾é¢˜ç»„ã€‚
- *2014.09 - 2015.06*, ç”µå­ä¿¡æ¯ä¸é€šä¿¡å­¦é™¢ï¼Œåä¸­ç§‘æŠ€å¤§å­¦ï¼Œç¡•å£«åšå£«ç ”ç©¶ç”Ÿï¼Œå›½å®¶æ°é’ç™½ç¿”æ•™æˆè¯¾é¢˜ç»„ã€‚
- *2010.09 - 2014.06*, ç‰©ç†å­¦é™¢ï¼Œä¸­å—å¤§å­¦ï¼Œæœ¬ç§‘ç”Ÿï¼Œé™¢é•¿åˆ˜é›„é£æ•™æˆã€‚

æˆ‘çš„ç ”ç©¶æ–¹å‘ä¸ºé‡å¤§ç–¾ç—…äººå·¥æ™ºèƒ½è¾…åŠ©ç­›æŸ¥ä¸æ‰‹æœ¯æ²»ç–—ï¼ˆè¿‘å‡ å¹´ä¸»è¦èšç„¦äºå¾®åˆ›å¤–ç§‘ã€æ¶ˆåŒ–å†…é•œç­‰ï¼‰ã€‚æˆ‘æ›¾è·è¯„æ­¦æ±‰å¸‚ä¼˜ç§€é’å¹´äººæ‰, æ ¡æ•™å¸ˆå…ˆè¿›å…¸å‹åŸ¹è‚²å¯¹è±¡å’Œä¼˜ç§€å…±äº§å…šå‘˜ç­‰è£èª‰ç§°å·ã€‚

è¿‘äº”å¹´ï¼Œæˆ‘ä¸»æŒäº†å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®å’Œé¢ä¸Šé¡¹ç›®å„1é¡¹ï¼Œæ‹…ä»»ç§‘æŠ€éƒ¨é’å¹´ç§‘å­¦å®¶é¡¹ç›®è¯¾é¢˜è´Ÿè´£äººï¼ˆæ€»æ’åç¬¬äºŒï¼‰ï¼Œå¹¶ä¸»æŒäº†æ­¦æ±‰å¸‚ç§‘æŠ€é‡å¤§ä¸“é¡¹â€œå¡è„–å­â€æŠ€æœ¯æ”»å…³è¯¾é¢˜ã€‚æˆ‘çš„ç ”ç©¶æˆæœã€ŠåŸºäºæ·±åº¦å­¦ä¹ çš„å† çŠ¶åŠ¨è„‰ã€è‚ºåŠ¨è„‰CTAè¾…åŠ©è¯Šæ–­ç³»ç»Ÿçš„ç ”ç©¶åŠä¸´åºŠåº”ç”¨ã€‹è·å¾—çœç§‘æŠ€è¿›æ­¥äºŒç­‰å¥–ï¼›ã€Šé¢å‘è„‘èƒ¶è´¨ç˜¤æ‰‹æœ¯çš„æ–°å‹äººå·¥æ™ºèƒ½ç¥ç»å¤–ç§‘ç²¾å‡†æ‰‹æœ¯ç³»ç»Ÿã€‹å…¥é€‰æ¹–åŒ—çœäººå·¥æ™ºèƒ½é‡å¤§åˆ›æ–°æˆæœï¼ˆåœºæ™¯ï¼‰ï¼Œå¹¶è¢«å¤®è§†ã€ã€Šé•¿æ±Ÿæ—¥æŠ¥ã€‹ç­‰åª’ä½“æŠ¥é“ã€‚

è¿‘äº”å¹´ï¼Œæˆ‘ä»¥ç¬¬ä¸€ä½œè€…æˆ–é€šè®¯ä½œè€…å‘è¡¨30ä½™ç¯‡é«˜æ°´å¹³è®ºæ–‡ï¼Œå…¶ä¸­åŒ…æ‹¬6ç¯‡å½±å“å› å­å¤§äº10çš„é¡¶çº§æœŸåˆŠè®ºæ–‡ï¼ˆMedical Image Analysis, IEEE Transactions on Medical Imagingï¼‰ï¼Œä»¥åŠ25ç¯‡å‘è¡¨äºIEEE JBHIã€NeurIPSã€ICCVã€MICCAIã€AAAIã€IJCAIã€ACM MMç­‰å›½é™…é¡¶çº§æœŸåˆŠä¸ä¼šè®®ã€‚æ­¤å¤–ï¼Œæˆ‘å·²è·æˆæƒæˆ–å…¬å¼€å‘æ˜ä¸“åˆ©10ä½™é¡¹ã€‚


# ğŸ”¥ é‡è¦äº‹ä»¶
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``NeurIPS``ä¼šè®®ï¼ˆCCF-Aï¼‰æ¥æ”¶ï¼Œç¥è´ºæ¨å‡¯ç¿”ï¼ 
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``JBHI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºTop5%ï¼‰æ¥æ”¶ï¼Œç¥è´ºå•æ–‡å¥‡ï¼ 
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``ACM MM``ä¼šè®®ï¼ˆCCF-Aï¼‰æ¥æ”¶ï¼Œç¥è´ºææ¬£ã€æ¨å‡¯ç¿”ï¼ 
- *2025.06*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``ICCV``ä¼šè®®ï¼ˆCCF-Aï¼‰æ¥æ”¶ï¼Œç¥è´ºæ¨å‡¯ç¿”ã€ææ¬£ï¼
- *2025.06*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``JBHI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºTop5%ï¼‰æ¥æ”¶ï¼Œç¥è´ºæ®µç„¶ï¼ç‰¹åˆ«æ„Ÿè°¢ç‹å¹³å®‰æ•™æˆã€è£´ä½³ä¼¦åšå£«çš„å¤§åŠ›æ”¯æŒï¼ 
- *2025.05*: &nbsp;ğŸ‰ğŸ‰ ä¸¤ç¯‡æœ¬äººé€šè®¯``MICCAI``ä¼šè®®ï¼ˆCCF-Bï¼‰æå‰æ¥æ”¶ï¼ˆæ¥æ”¶ç‡<9%ï¼‰ï¼Œç¥è´ºå‘¨æƒã€ç½—æ•¢ã€ç‹ç¦ç«ã€èƒ¡å¼ºï¼
- *2025.04*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``JBHI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºï¼‰æ¥æ”¶ï¼Œç¥è´ºå‘¨æƒï¼
- *2025.02*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººä¸€ä½œ``MedIA``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦1åŒºTop5%ï¼Œå½±å“å› å­>10ï¼‰æ¥æ”¶ï¼ 
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ ä¸‰ç¯‡æœ¬äººé€šè®¯``ICASSP``ä¼šè®®ï¼ˆCCF-Bï¼‰æ¥æ”¶ï¼Œç¥è´ºå•æ–‡å¥‡ã€èƒ¡å¼ºã€æ¨å‡¯ç¿”ï¼ 
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``AAAI``ä¼šè®®ï¼ˆCCF-Aï¼‰æ¥æ”¶ï¼Œç¥è´ºèƒ¡å¼ºï¼ 
- *2024.10*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``JBHI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºï¼‰æ¥æ”¶ï¼Œç¥è´ºå½­æ”¾ã€çŸ³æ´ªå®½ã€ä½•è¯—æ³‰ï¼ 
- *2024.10*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``BIBM``ä¼šè®®ï¼ˆCCF-Bï¼‰æ¥æ”¶ï¼Œç¥è´ºå‘¨ç€›ï¼
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``BIBM``ä¼šè®®ï¼ˆCCF-Bï¼‰æ¥æ”¶ï¼Œç¥è´ºæ¨å‡¯ç¿”ï¼
- *2024.06*: &nbsp;ğŸ‰ğŸ‰ ä¸¤ç¯‡æœ¬äººé€šè®¯``MICCAI``ä¼šè®®ï¼ˆCCF-Bï¼‰æ¥æ”¶ï¼Œå…¶ä¸­ä¸€ç¯‡ä¸ºå£å¤´æ±‡æŠ¥ï¼ˆæ¥æ”¶ç‡<3%ï¼‰ï¼Œç¥è´ºèƒ¡å¼ºã€å´å´‡ç‚œï¼
- *2024.02*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``TMI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦1åŒºTop5%ï¼Œå½±å“å› å­>10ï¼‰æ¥æ”¶ï¼Œç¥è´ºå‘¨æƒï¼
- *2023.10*: &nbsp;ğŸ‰ğŸ‰ ä¸¤ç¯‡æœ¬äººé€šè®¯``BIBM``ä¼šè®®ï¼ˆCCF-Bï¼‰æ¥æ”¶ï¼Œç¥è´ºæ™è”ç›ˆã€å•æ–‡å¥‡ï¼
- *2023.05*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººå…±ä¸€``TMI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦1åŒºTop5%ï¼Œå½±å“å› å­>10ï¼‰æ¥æ”¶ï¼Œç¥è´ºçŸ³æ´ªå®½ï¼
- *2023.04*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººä¸€ä½œ``IJCAI``ä¼šè®®ï¼ˆCCF-Aï¼‰æ¥æ”¶ï¼
- *2022.12*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``JBHI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºï¼‰æ¥æ”¶ï¼Œç¥è´ºæ¢æ„¿æ€€ã€å•è¿›é‘«ï¼
- *2022.11*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººé€šè®¯``AAAI``ä¼šè®®ï¼ˆCCF-Aï¼‰æ¥æ”¶ï¼Œç¥è´ºå•è¿›é‘«ã€æ›¾æ™“å®‡ï¼ç‰¹åˆ«æ„Ÿè°¢æ¯•ä¸šç”Ÿç‹èƒœçš„å¸®åŠ©ï¼
- *2022.04*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººå…±ä¸€``TMI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦1åŒºTop5%ï¼Œå½±å“å› å­>10ï¼‰æ¥æ”¶ï¼Œç¥è´ºå•è¿›é‘«ï¼
- *2021.07*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººå…±ä¸€``ACM MM``ä¼šè®®ï¼ˆCCF-Aï¼‰æ¥æ”¶ï¼Œç¥è´ºçŸ³æ´ªå®½ï¼
- *2021.06*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººå…±ä¸€``MICCAI``ä¼šè®®ï¼ˆCCF-Bï¼‰æ¥æ”¶ï¼Œç¥è´ºå†¼ä¿Šæ—ï¼
- *2020.03*: &nbsp;ğŸ‰ğŸ‰ ä¸€ç¯‡æœ¬äººä¸€ä½œ``TMI``æœŸåˆŠï¼ˆä¸­ç§‘é™¢åŒ»å­¦1åŒºTop5%ï¼Œå½±å“å› å­>10ï¼‰æ¥æ”¶ï¼



# ğŸ“ ä¸€ä½œä¸é€šè®¯çš„è®ºæ–‡ 
### (Note: <span style="color:#0D6EFD">&#42;</span>: é€šè®¯ä½œè€…, <span style="color:#FFA500">&#8224;</span>: å…±åŒä¸€ä½œ)

## ğŸ“† 2025å¹´ï¼š
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Medical Image Analysis 2025<span style="color:red">ï¼ˆä¸­ç§‘é™¢åŒ»å­¦1åŒºTop5%ï¼Œå½±å“å› å­>10ï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MonoPCC: Photometric-invariant Cycle Constraint for Monocular Depth Estimation of Endoscopic Images]()

**Zhiwei Wang**<span style="color:#0D6EFD">&#8224;</span>, Ying Zhou<span style="color:#0D6EFD">&#8224;</span>, Shiquan He, Ting Li, Fan Huang, Qiang Ding, Xinxia Feng, Mei Liu, Qiang Li<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025<span style="color:red">ï¼ˆCCF-Aï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FSI-Edit: Frequency and Stochasticity Injection for Flexible Diffusion-Based Image Editing]()

Kaixiang Yang<span style="color:#0D6EFD">&#8224;</span>, Xin Li<span style="color:#0D6EFD">&#8224;</span>, Yuxi Li, Qiang Li, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025<span style="color:red">ï¼ˆCCF-Aï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CoStoDet-DDPM: Collaborative Training of Stochastic and Deterministic Models Improves Surgical Workflow Anticipation and Recognition]()

Kaixiang Yang<span style="color:#0D6EFD">&#8224;</span>, Xin Li<span style="color:#0D6EFD">&#8224;</span>, Qiang Li<span style="color:#FFA500">&#42;</span>, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2025<span style="color:red">ï¼ˆCCF-Aï¼‰</span></div><img src='images/MonoBox-500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MonoBox: Tightness-free Box-supervised Polyp Segmentation using Monotonicity Constraint](https://arxiv.org/abs/2404.01188)

Qiang Hu, Zhenyu Yi, Ying Zhou, Fan Huang, Mei Liu, Qiang Li, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**](https://github.com/Huster-Hq/MonoBox)
- MonoBox proposes a novel monotonicity constraint to liberate the training of existing MIL-based box-supervised segmentation methods from the user-unfriendly box-tightness assumption. It is plug-and-play and can improve the tolerance of any MIL-based box-supervised segmentation methods (e.g., BoxInst, BoxLevelSet, IBoxCLA, etc.) to tightness-free box annotations in any scenarios (e.g., common, medical, etc.).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2025<span style="color:red">ï¼ˆCCF-Aï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional Diffusion Model]()

Xin Li<span style="color:#0D6EFD">&#8224;</span>, Kaixiang Yang<span style="color:#0D6EFD">&#8224;</span>, Qiang Li, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JBHI 2025<span style="color:red">ï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºTop5%ï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Single-slice Semi-supervised 3D Medical Image Segmentation via Correlation Information Enhancement and Hybrid Pseudo Mask Generation]()

Quan Zhou, Mingwei Wen, Mingyue Ding, Yixin Su, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>;

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JBHI 2025<span style="color:red">ï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºTop5%ï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Boosting Few-shot Semantic Segmentation of 3D Medical Images via Collaborative Slice Alignment]()

Ran Duan<span style="color:#0D6EFD">&#8224;</span>, Jialun Pei<span style="color:#0D6EFD">&#8224;</span>, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>, Ruiheng Zhang, Qiang Li, Pheng-Ann Heng

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JBHI 2025<span style="color:red">ï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºTop5%ï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Improving 3D Thin Vessel Segmentation in Brain TOF-MRA via a Dual-space Context-Aware Network]()

Wenqi Shan, Xudong Li, Qiang Li<span style="color:#FFA500">&#42;</span>, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MICCAI 2025<span style="color:red">ï¼ˆCCF-Bï¼Œæå‰æ¥æ”¶ï¼Œæ¥æ”¶ç‡9%ï¼‰</span></div><img src='images/DADA.gif' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Targeted False Positive Synthesis via Detector-guided Adversarial Diffusion Attacker for Robust Polyp Detection](https://arxiv.org/abs/2506.18134)

Quan Zhou<span style="color:#0D6EFD">&#8224;</span>, Gan Luo<span style="color:#0D6EFD">&#8224;</span>, Qiang Hu<span style="color:#FFA500">&#42;</span>, Qingyong Zhang, Yinjiao Tian, Qiang Li, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**](https://github.com/Huster-Hq/DADA)
- To reduce false positive predictions of polyp detectors in clinical applications, we propose a novel image synthesis method, namely DADA, that integrates diffusion models with adversarial attacks, focusing on generating high-value negative samples capable of effectively misleading polyp detectors.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MICCAI 2025<span style="color:red">ï¼ˆCCF-Bï¼Œæå‰æ¥æ”¶ï¼Œæ¥æ”¶ç‡9%ï¼‰</span></div><img src='images/ADD-500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Holistic White-light Polyp Classification via Alignment-free Dense Distillation of Auxiliary Optical Chromoendoscopy](https://arxiv.org/abs/2505.19319)

Qiang Hu<span style="color:#0D6EFD">&#8224;</span>, Qimei Wang<span style="color:#0D6EFD">&#8224;</span>, Jia Chen, Xuantao Ji, Mei Liu, Qiang Li<span style="color:#FFA500">&#42;</span>, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**](https://github.com/Huster-Hq/ADD)
- We propose a novel holistic WLI polyp classification framework, which mainly prpose a novel module, Alignment-free Dense Distillation (ADD), to leverage NBI knowledge to assist holistic WLI polyp classifier without requiring geometric priors (e.g., polyp locations).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2025<span style="color:red">ï¼ˆCCF-Bï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DACAT: Dual-stream Adaptive Clip-aware Time Modeling for Robust Online Surgical Phase Recognition]()

Kaixiang Yang, Qiang Li, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2025<span style="color:red">ï¼ˆCCF-Bï¼‰</span></div><img src='images/PSDNet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[First-frame Supervised Video Polyp Segmentation via Propagative and Semantic Dual-teacher Network](https://arxiv.org/abs/2412.16503)

Qiang Hu, Mei Liu, Qiang Li, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**](https://github.com/Huster-Hq/PSDNet)
- PSDNet greatly reduces the labeling costs of training video segmentation models, which require only one frame of annotation on each video, regardless of the length. It benefits from the existing powerful fundamental video segmentation models (e.g., XMem and SAM 2).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2025<span style="color:red">ï¼ˆCCF-Bï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SPNet: Sparse-mask Prompt-learning Network for Cerebrovascular Segmentation]()

Wenqi Shan, Qiang Li<span style="color:#FFA500">&#42;</span>, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>

## ğŸ“† 2024å¹´ï¼š

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMI 2024<span style="color:red">ï¼ˆä¸­ç§‘é™¢åŒ»å­¦1åŒºTop5%ï¼Œå½±å“å› å­>10ï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Robust Semi-supervised 3D Medical Image Segmentation with Diverse Joint-task Learning and Decoupled Inter-student Learning]()

Quan Zhou, Bin Yu, Feng Xiao, Mingyue Ding, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>, Xuming Zhang<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JBHI 2024<span style="color:red">ï¼ˆä¸­ç§‘é™¢åŒ»å­¦ä¿¡æ¯1åŒºï¼‰</span></div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Fine-grained Temporal Site Monitoring in EGD Streams via Visual Time-aware Embedding and Vision-text Asymmetric Coworking]()

Fang Peng<span style="color:#0D6EFD">&#8224;</span>, Hongkuan Shi<span style="color:#0D6EFD">&#8224;</span>, Shiquan He<span style="color:#0D6EFD">&#8224;</span>, Qiang Li, Ting Li, Fan Huang, Xinxia Feng, Mei Liu, Jiazhi Liao, Qiang Li<span style="color:#FFA500">&#42;</span>, **Zhiwei Wang**<span style="color:#FFA500">&#42;</span>

[**Code**]()
</div>
</div>


# ğŸ†ï¸ è£èª‰ä¸è·å¥–
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ å­¦æœ¯å…¼èŒä¸æœåŠ¡
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
